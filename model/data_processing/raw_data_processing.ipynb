{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda2f8d8",
   "metadata": {},
   "source": [
    "# Raw Data Processing Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026873f",
   "metadata": {},
   "source": [
    "10am, 7/11/25: Uses raw data to make a processed df & similarity matrix that can be used by the server for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31341edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "726ff525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_colname(df):\n",
    "    \"\"\"\n",
    "    Sort dataframe columns with the following rules:\n",
    "    1. Columns named \"id\" or \"name\"\n",
    "    2. Columns without underscores come first (sorted alphabetically)\n",
    "    3. Columns with underscores come after (sorted by prefix frequency, then alphabetically)\n",
    "       - Least frequent prefixes come first\n",
    "    \"\"\"\n",
    "    # Get the list of column names\n",
    "    columns = list(df.columns)\n",
    "    \n",
    "    # Special columns that should always come first\n",
    "    special_columns = []\n",
    "    if 'id' in columns:\n",
    "        special_columns.append('id')\n",
    "        columns.remove('id')\n",
    "    if 'name' in columns:\n",
    "        special_columns.append('name')\n",
    "        columns.remove('name')\n",
    "    \n",
    "    # Separate remaining columns into those with and without underscores\n",
    "    columns_without_underscore = [col for col in columns if '_' not in col]\n",
    "    columns_with_underscore = [col for col in columns if '_' in col]\n",
    "    \n",
    "    # Sort columns without underscores alphabetically\n",
    "    columns_without_underscore.sort()\n",
    "    \n",
    "    # For columns with underscores, group by prefix\n",
    "    prefix_groups = {}\n",
    "    for col in columns_with_underscore:\n",
    "        prefix = col.split('_')[0] + '_'\n",
    "        if prefix not in prefix_groups:\n",
    "            prefix_groups[prefix] = []\n",
    "        prefix_groups[prefix].append(col)\n",
    "    \n",
    "    # Sort prefixes by frequency (least frequent first)\n",
    "    sorted_prefixes = sorted(prefix_groups.keys(), key=lambda x: len(prefix_groups[x]))\n",
    "    \n",
    "    # Build the final list of columns with underscores, sorted by prefix frequency then alphabetically\n",
    "    columns_with_underscore_sorted = []\n",
    "    for prefix in sorted_prefixes:\n",
    "        # Sort columns within each prefix group alphabetically\n",
    "        prefix_groups[prefix].sort()\n",
    "        columns_with_underscore_sorted.extend(prefix_groups[prefix])\n",
    "    \n",
    "    # Combine all the sorted groups, with special columns first\n",
    "    sorted_columns = special_columns + columns_without_underscore + columns_with_underscore_sorted\n",
    "    \n",
    "    # Return the dataframe with sorted columns\n",
    "    return df[sorted_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b49eb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Extract tags into a structured format\n",
    "def process_tags(tags_str):\n",
    "    # Handle empty or null values\n",
    "    if not tags_str or tags_str == '[]' or tags_str == '{}':\n",
    "        return {}\n",
    "    \n",
    "    # Convert the string representation to a Python object\n",
    "    if isinstance(tags_str, str):\n",
    "        try:\n",
    "            # Replace single quotes with double quotes for valid JSON\n",
    "            tags_obj = json.loads(tags_str.replace(\"'\", '\"'))\n",
    "        except json.JSONDecodeError:\n",
    "            # Alternative approach if the above fails\n",
    "            try:\n",
    "                tags_obj = eval(tags_str)  # Be careful with eval - only use with trusted data\n",
    "            except:\n",
    "                return {}  # Return empty dict if parsing fails\n",
    "    else:\n",
    "        tags_obj = tags_str  # If it's already a Python object\n",
    "    \n",
    "    # Handle the case where tags_obj is a list\n",
    "    if isinstance(tags_obj, list):\n",
    "        return {}  # Return empty dictionary for list entries\n",
    "    \n",
    "    # Now we're sure tags_obj is a dictionary\n",
    "    # Normalize tag counts by dividing by the sum\n",
    "    total = sum(tags_obj.values()) if tags_obj else 1\n",
    "    return {tag: count/total for tag, count in tags_obj.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58e3c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert multi-genre strings to one-hot encoded features\n",
    "def expand_genres_to_columns(df):\n",
    "    # Assuming genres are stored as comma-separated strings\n",
    "    # If they're in another format (lists, etc.), adjust the splitting logic\n",
    "    all_genres = set()\n",
    "    for genres in df['genre']:\n",
    "        if isinstance(genres, str):\n",
    "            all_genres.update([g.strip() for g in genres.split(',')])\n",
    "    \n",
    "    # Create binary columns for each genre\n",
    "    for genre in all_genres:\n",
    "        column_name = f'genre_{genre.lower().replace(\" \", \"_\")}'\n",
    "        df[column_name] = df['genre'].apply(\n",
    "            lambda x: 1 if isinstance(x, str) and genre in x else 0\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function to expand the normalized tags into columns (optimized version)\n",
    "def expand_tags_to_columns(df):\n",
    "    # First, collect all unique tags across all games\n",
    "    all_tags = set()\n",
    "    for tags_dict in df['normalized_tags']:\n",
    "        all_tags.update(tags_dict.keys())\n",
    "    \n",
    "    # Create column names with 'tags_' prefix and lowercase\n",
    "    tag_columns = ['tags_' + tag.lower() for tag in all_tags]\n",
    "    \n",
    "    # Create a dictionary to hold the tag data\n",
    "    tag_data = {col: np.zeros(len(df), dtype=float) for col in tag_columns}\n",
    "    \n",
    "    # Fill in the values from normalized_tags (much more efficient)\n",
    "    for idx, tags_dict in enumerate(df['normalized_tags']):\n",
    "        for tag, value in tags_dict.items():\n",
    "            tag_data['tags_' + tag.lower()][idx] = value\n",
    "    \n",
    "    # Create the tag dataframe all at once\n",
    "    tag_df = pd.DataFrame(tag_data, index=df.index)\n",
    "    \n",
    "    # Concatenate the original dataframe with the tag dataframe\n",
    "    result_df = pd.concat([df, tag_df], axis=1)\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "912e0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    print(\"preprocessing data...\")\n",
    "    # Create a copy to avoid modifying the original TODO use original later\n",
    "    processed_df = df.copy()\n",
    "    processed_df = processed_df.drop(['appid', 'average_forever', 'average_2weeks', 'median_forever', 'median_2weeks', 'userscore', 'score_rank', 'languages'], axis=1)\n",
    "    processed_df = pd.get_dummies(processed_df, columns=['owners', \"publisher\", \"developer\"])\n",
    "    \n",
    "    # Handle missing values in price\n",
    "    processed_df['price'] = processed_df['price'].fillna(processed_df['price'].median())\n",
    "    \n",
    "    # Handle missing values\n",
    "    processed_df = processed_df.fillna({'positive': 0, 'negative': 0, 'owners': 0, 'ccu': 0})\n",
    "\n",
    "    # Normalize tag values\n",
    "    processed_df['normalized_tags'] = processed_df['tags'].apply(process_tags)\n",
    "    return processed_df\n",
    "\n",
    "def engineer_features(df):\n",
    "    print(\"Engineering features...\")\n",
    "    # Create derived features\n",
    "    df['review_ratio'] = df['positive'] / (df['positive'] + df['negative'] + 1)  # Add 1 to avoid division by zero\n",
    "    df['discount_percentage'] = (df['initialprice'] - df['price']) / (df['initialprice'] + 0.01)\n",
    "\n",
    "    # Scale the price and positive features\n",
    "    scaler = StandardScaler()\n",
    "    df['price_scaled'] = scaler.fit_transform(df[['price']])\n",
    "    # Scale these - not so much info loss since ccu column contains raw counts\n",
    "    df['positive_scaled'] = scaler.fit_transform(df[['positive']])\n",
    "    df['negative_scaled'] = scaler.fit_transform(df[['negative']])\n",
    "\n",
    "    df = expand_genres_to_columns(df)\n",
    "    df = expand_tags_to_columns(df)\n",
    "\n",
    "    df = df.drop(['positive', 'negative', 'discount', 'initialprice', 'normalized_tags', 'tags', 'genre', 'price'], axis=1)\n",
    "    \n",
    "    # Could play around with dropping some features here\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7004f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(df, features=None, feature_weights=None, category_prefixes=None):\n",
    "    \"\"\"\n",
    "    Build a similarity matrix with dynamic weighting for categorical features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame containing features\n",
    "    features : list, optional\n",
    "        List of feature names to use. If None, all columns are used.\n",
    "    feature_weights : dict, optional\n",
    "        Dictionary mapping feature names or category prefixes to weights\n",
    "    category_prefixes : list, optional\n",
    "        List of prefixes that identify categorical features (e.g., 'genre_', 'tags_')\n",
    "        These features will have weights distributed only among categories an item belongs to\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Similarity matrix as a DataFrame with indices matching the input DataFrame\n",
    "    \"\"\"\n",
    "    # If no features specified, use all columns in the dataframe\n",
    "    if features is None:\n",
    "        features = df.columns.tolist()\n",
    "    \n",
    "    # Default empty list for category_prefixes if not provided\n",
    "    if category_prefixes is None:\n",
    "        category_prefixes = []\n",
    "    \n",
    "    # Create a copy of the feature matrix to avoid modifying the original\n",
    "    weighted_matrix = df[features].copy().values.astype(float)\n",
    "    \n",
    "    # Group features by category prefix\n",
    "    prefix_features = {}\n",
    "    for prefix in category_prefixes:\n",
    "        prefix_features[prefix] = [f for f in features if f.startswith(prefix)]\n",
    "    \n",
    "    # Process each row individually to apply dynamic weighting\n",
    "    for i in range(len(df)):\n",
    "        # For each category prefix, distribute weight only among categories the item belongs to\n",
    "        for prefix in category_prefixes:\n",
    "            prefix_weight = feature_weights.get(prefix, 0) if feature_weights else 0\n",
    "            prefix_cols = prefix_features[prefix]\n",
    "            \n",
    "            if not prefix_cols:\n",
    "                continue\n",
    "                \n",
    "            # Count how many categories this item belongs to in this prefix\n",
    "            item_category_count = sum(df.iloc[i][col] == 1 for col in prefix_cols)\n",
    "            \n",
    "            if item_category_count > 0:\n",
    "                # Distribute weight only among categories the item belongs to\n",
    "                for j, col in enumerate(features):\n",
    "                    if col in prefix_cols:\n",
    "                        col_idx = features.index(col)\n",
    "                        if df.iloc[i][col] == 1:  # If item belongs to this category\n",
    "                            weighted_matrix[i, col_idx] = prefix_weight / item_category_count\n",
    "                        else:\n",
    "                            weighted_matrix[i, col_idx] = 0\n",
    "        \n",
    "        # Apply weights to non-category features\n",
    "        for j, feature in enumerate(features):\n",
    "            if not any(feature.startswith(prefix) for prefix in category_prefixes):\n",
    "                if feature_weights and feature in feature_weights:\n",
    "                    weighted_matrix[i, j] *= feature_weights[feature]\n",
    "    \n",
    "    # Calculate cosine similarity using the weighted matrix\n",
    "    similarity_matrix = cosine_similarity(weighted_matrix)\n",
    "    \n",
    "    # Create a DataFrame for easier indexing\n",
    "    similarity_df = pd.DataFrame(\n",
    "        similarity_matrix,\n",
    "        index=df.index,\n",
    "        columns=df.index\n",
    "    )\n",
    "    \n",
    "    return similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72268d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\wasadmin\\AppData\\Local\\Temp\\3\\ipykernel_11984\\2461612335.py:1: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  df = pd.read_csv(\"../../Data\\Top 1000 Steam Games 2023 export 2025-07-09 14-37-02.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>score_rank</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>userscore</th>\n",
       "      <th>owners</th>\n",
       "      <th>average_forever</th>\n",
       "      <th>average_2weeks</th>\n",
       "      <th>median_forever</th>\n",
       "      <th>median_2weeks</th>\n",
       "      <th>price</th>\n",
       "      <th>initialprice</th>\n",
       "      <th>discount</th>\n",
       "      <th>languages</th>\n",
       "      <th>genre</th>\n",
       "      <th>ccu</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Valve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216345</td>\n",
       "      <td>5530</td>\n",
       "      <td>0</td>\n",
       "      <td>10,000,000 .. 20,000,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>English, French, German, Italian, Spanish - Sp...</td>\n",
       "      <td>Action</td>\n",
       "      <td>10775</td>\n",
       "      <td>{'Action': 5448, 'FPS': 4862, 'Multiplayer': 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid            name developer publisher  score_rank  positive  negative  \\\n",
       "0     10  Counter-Strike     Valve     Valve         NaN    216345      5530   \n",
       "\n",
       "   userscore                    owners  average_forever  average_2weeks  \\\n",
       "0          0  10,000,000 .. 20,000,000                0               0   \n",
       "\n",
       "   median_forever  median_2weeks  price  initialprice  discount  \\\n",
       "0               0              0    999           999         0   \n",
       "\n",
       "                                           languages   genre    ccu  \\\n",
       "0  English, French, German, Italian, Spanish - Sp...  Action  10775   \n",
       "\n",
       "                                                tags  \n",
       "0  {'Action': 5448, 'FPS': 4862, 'Multiplayer': 3...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../Data\\Top 1000 Steam Games 2023 export 2025-07-09 14-37-02.csv\")\n",
    "# df = df[:20]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f71f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "Engineering features...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ccu</th>\n",
       "      <th>review_ratio</th>\n",
       "      <th>discount_percentage</th>\n",
       "      <th>price_scaled</th>\n",
       "      <th>positive_scaled</th>\n",
       "      <th>negative_scaled</th>\n",
       "      <th>owners_1,000,000 .. 2,000,000</th>\n",
       "      <th>owners_10,000,000 .. 20,000,000</th>\n",
       "      <th>owners_100,000,000 .. 200,000,000</th>\n",
       "      <th>...</th>\n",
       "      <th>developer_id Software, Nightdive Studios, MachineGames</th>\n",
       "      <th>developer_mestiez</th>\n",
       "      <th>developer_peropero</th>\n",
       "      <th>developer_poncle</th>\n",
       "      <th>developer_tobyfox</th>\n",
       "      <th>developer_vanripper</th>\n",
       "      <th>developer_Łukasz Jakowski</th>\n",
       "      <th>developer_艺龙游戏</th>\n",
       "      <th>developer_鬼谷工作室</th>\n",
       "      <th>developer_（Hong Kong）GKD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>10775</td>\n",
       "      <td>0.975072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.314121</td>\n",
       "      <td>0.592214</td>\n",
       "      <td>-0.115509</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name    ccu  review_ratio  discount_percentage  price_scaled  \\\n",
       "0  Counter-Strike  10775      0.975072                  0.0     -0.314121   \n",
       "\n",
       "   positive_scaled  negative_scaled  owners_1,000,000 .. 2,000,000  \\\n",
       "0         0.592214        -0.115509                          False   \n",
       "\n",
       "   owners_10,000,000 .. 20,000,000  owners_100,000,000 .. 200,000,000  ...  \\\n",
       "0                             True                              False  ...   \n",
       "\n",
       "   developer_id Software, Nightdive Studios, MachineGames  developer_mestiez  \\\n",
       "0                                              False                   False   \n",
       "\n",
       "   developer_peropero  developer_poncle  developer_tobyfox  \\\n",
       "0               False             False              False   \n",
       "\n",
       "   developer_vanripper  developer_Łukasz Jakowski  developer_艺龙游戏  \\\n",
       "0                False                      False           False   \n",
       "\n",
       "   developer_鬼谷工作室  developer_（Hong Kong）GKD  \n",
       "0            False                     False  \n",
       "\n",
       "[1 rows x 1622 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = preprocess_data(df)\n",
    "\n",
    "processed_df = engineer_features(processed_df)\n",
    "\n",
    "\n",
    "# Define base features and category prefixes\n",
    "features_to_use = ['review_ratio', 'price_scaled', 'ccu', 'discount_percentage']\n",
    "category_prefixes = ['tags_', 'developer_', 'owners_', 'publisher_', 'genre_']\n",
    "\n",
    "# Add all columns with the specified prefixes in one pass\n",
    "for prefix in category_prefixes:\n",
    "    features_to_use.extend([col for col in df.columns if col.startswith(prefix)])\n",
    "\n",
    "# Define category weights\n",
    "category_weights = {\n",
    "    'tags_': 0.5,\n",
    "    'genre_': 0.4,\n",
    "    'developer_': 0.2,  # Default 0 if not specified in original\n",
    "    'review_ratio': 0.1,\n",
    "    'ccu': 0.05,\n",
    "    'owners_': 0.05,\n",
    "    'price_scaled': 0.1,\n",
    "    'publisher_': 0.05,  # Default 0 if not specified in original\n",
    "    'discount_percentage': 0.05  # Default 0 if not specified in original\n",
    "}\n",
    "\n",
    "# Count features by category for weight distribution\n",
    "prefix_counts = {prefix: sum(1 for col in features_to_use if col.startswith(prefix)) \n",
    "                for prefix in category_prefixes}\n",
    "\n",
    "# Create feature_weights dictionary in one pass\n",
    "feature_weights = {}\n",
    "for feature in features_to_use:\n",
    "    # Direct assignment for non-prefix features\n",
    "    if feature in category_weights:\n",
    "        feature_weights[feature] = category_weights[feature]\n",
    "    else:\n",
    "        # Find matching prefix and distribute weight\n",
    "        for prefix in category_prefixes:\n",
    "            if feature.startswith(prefix) and prefix_counts[prefix] > 0:\n",
    "                feature_weights[feature] = category_weights.get(prefix, 0) / prefix_counts[prefix]\n",
    "                break\n",
    "\n",
    "processed_df = sort_by_colname(processed_df)\n",
    "# Write processed data to parquet\n",
    "processed_df.to_parquet('../../Data/processed_games.parquet')\n",
    "\n",
    "\n",
    "# Call the function with the dictionary of weights\n",
    "similarity_df = build_similarity_matrix(processed_df, features_to_use, feature_weights)\n",
    "# Write processed data to parquet\n",
    "similarity_df.to_parquet('../../Data/games_similarity_matrix.parquet')\n",
    "\n",
    "\n",
    "processed_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82e9a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity check\n",
    "# for col in processed_df.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b324aaf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47796f9c",
   "metadata": {},
   "source": [
    "## Read in Data & Make Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "021d877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(game_idx, similarity_df, df, features_used, n=5):\n",
    "    print(f\"Getting recommendations for index {game_idx} and name {df['name'].iloc[game_idx]}\")\n",
    "    # Check if the game exists in our data\n",
    "    if game_idx not in similarity_df.index:\n",
    "        return f\"Game with index {game_idx} not found in the database.\"\n",
    "    # Get similarity scores for the game\n",
    "    similarity_scores = similarity_df.loc[game_idx].sort_values(ascending=False)\n",
    "    \n",
    "    # Get top N similar games (excluding the game itself)\n",
    "    similar_games = similarity_scores.iloc[1:n+1]\n",
    "    \n",
    "    # Get details of recommended games\n",
    "    recommendations = df.loc[similar_games.index]\n",
    "    \n",
    "    # Add similarity score to recommendations\n",
    "    recommendations = recommendations.copy()\n",
    "    recommendations['similarity_score'] = similar_games.values\n",
    "    \n",
    "    # Sort by similarity score\n",
    "    recommendations = recommendations.sort_values('similarity_score', ascending=False)\n",
    "    # print(recommendations.head())\n",
    "    \n",
    "    return recommendations[features_used]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33fd08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a recommendation function with pre-loaded data\n",
    "def recommend_by_index(game_idx, n=5):\n",
    "    return get_recommendations(game_idx, similarity_df, processed_df, features_to_use, n)\n",
    "\n",
    "# Alternative function that accepts a game name\n",
    "def recommend_by_name(game_name, n=5):\n",
    "    # Find the game index\n",
    "    if game_name not in processed_df['name'].values:\n",
    "        return f\"Game '{game_name}' not found in the database.\"\n",
    "    \n",
    "    game_idx = processed_df[processed_df['name'] == game_name].index[0]\n",
    "    print(\"Game idx from rec by name lookup: \", game_idx)\n",
    "    return get_recommendations(game_idx, similarity_df, processed_df, features_to_use, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e559deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending for game at index 18 with details: \n",
      "appid                                                            420\n",
      "name                                        Half-Life 2: Episode Two\n",
      "developer                                                      Valve\n",
      "publisher                                                      Valve\n",
      "score_rank                                                       NaN\n",
      "positive                                                       33820\n",
      "negative                                                        1024\n",
      "userscore                                                          0\n",
      "owners                                       5,000,000 .. 10,000,000\n",
      "average_forever                                                    0\n",
      "average_2weeks                                                     0\n",
      "median_forever                                                     0\n",
      "median_2weeks                                                      0\n",
      "price                                                            799\n",
      "initialprice                                                     799\n",
      "discount                                                           0\n",
      "languages          English, French, German, Russian, Danish, Dutc...\n",
      "genre                                                         Action\n",
      "ccu                                                              280\n",
      "tags               {'FPS': 915, 'Action': 678, 'Sci-fi': 567, 'Si...\n",
      "Name: 18, dtype: object\n",
      "review_ratio             0.970584\n",
      "price_scaled            -0.442804\n",
      "ccu                    280.000000\n",
      "discount_percentage      0.000000\n",
      "Name: 18, dtype: float64\n",
      "Getting recommendations for index 18 and name Half-Life 2: Episode Two\n",
      "Recommendations for game at index 18 based on ['review_ratio', 'price_scaled', 'ccu', 'discount_percentage'] with weights {'review_ratio': 0.1, 'price_scaled': 0.1, 'ccu': 0.05, 'discount_percentage': 0.05}:\n",
      "     review_ratio  price_scaled  ccu  discount_percentage\n",
      "532      0.935581     -0.314121  265             0.000000\n",
      "134      0.941392     -0.314121  257             0.000000\n",
      "47       0.943534     -0.314121  289             0.000000\n",
      "266      0.973258     -0.314121  250             0.000000\n",
      "199      0.952846     -0.635828  281             0.000000\n",
      "98       0.857127     -0.314121  292             0.000000\n",
      "503      0.886753     -0.635828  310             0.000000\n",
      "850      0.872747     -0.635828  278             0.000000\n",
      "394      0.851010     -0.314121  197             0.000000\n",
      "169      0.958769     -0.635828  313             0.500495\n",
      "Game idx from rec by name lookup:  18\n",
      "Getting recommendations for index 18 and name Half-Life 2: Episode Two\n",
      "\n",
      "Recommendations for 'Half-Life 2: Episode Two' based on ['review_ratio', 'price_scaled', 'ccu', 'discount_percentage'] with weights {'review_ratio': 0.1, 'price_scaled': 0.1, 'ccu': 0.05, 'discount_percentage': 0.05}:\n",
      "     review_ratio  price_scaled  ccu  discount_percentage\n",
      "532      0.935581     -0.314121  265                  0.0\n",
      "134      0.941392     -0.314121  257                  0.0\n",
      "47       0.943534     -0.314121  289                  0.0\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations by index\n",
    "game_idx = 18\n",
    "print(f\"Recommending for game at index {game_idx} with details: \\n{df.iloc[game_idx]}\")\n",
    "print(processed_df[features_to_use].iloc[game_idx])\n",
    "\n",
    "recommendations_by_idx = recommend_by_index(game_idx, n=10)\n",
    "print(f\"Recommendations for game at index {game_idx} based on {features_to_use} with weights {feature_weights}:\")\n",
    "print(recommendations_by_idx)\n",
    "\n",
    "# Get recommendations by name\n",
    "game_name = 'Half-Life 2: Episode Two'\n",
    "recommendations_by_name = recommend_by_name(game_name, n=3)\n",
    "print(f\"\\nRecommendations for '{game_name}' based on {features_to_use} with weights {feature_weights}:\")\n",
    "print(recommendations_by_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
